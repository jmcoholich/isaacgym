seed: -1
policy: # only works for MlpPolicy right now
  pi_hid_sizes: [256, 128, 64]
  vf_hid_sizes: [256, 128, 64]
  # pi_hid_sizes: [128, 128]
  # vf_hid_sizes: [128, 128]
  activation: tanh # can be elu, relu, selu, crelu, lrelu, tanh, sigmoid
learn:
  agent_name: pytorch_ppo
  resume: 0
  test: False
  print_log: True
  save_interval: 10 # check for potential saves every this many iterations

  # rollout params
  max_iterations: 5000

  # training params
  cliprange: 0.2
  ent_coef: -0.001
  nsteps: 10  # number of steps per env
  noptepochs: 8
  nminibatches: 2 # this is per agent
  optim_stepsize: 3.e-4 # 3e-4 isefault for single agent training with constant schedule
  # schedule: adaptive # could be adaptive or linear or fixed
  gamma: 0.99
  lam: 0.95
  init_noise_std: 1.0

  log_interval: 100
